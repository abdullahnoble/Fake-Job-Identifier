{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacdccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb4f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marketing intern u ny new york food created gr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customer service cloud video production nz auc...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commissioning machinery assistant cma u ia wev...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>account executive washington dc u dc washingto...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill review manager u fl fort worth spotsource...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  fraudulent\n",
       "0  marketing intern u ny new york food created gr...         0.0\n",
       "1  customer service cloud video production nz auc...         0.0\n",
       "2  commissioning machinery assistant cma u ia wev...         0.0\n",
       "3  account executive washington dc u dc washingto...         0.0\n",
       "4  bill review manager u fl fort worth spotsource...         0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('corpus_lemm.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c978b80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bb4503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          False\n",
       "fraudulent     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e1f95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.head()\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acbd90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ana\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd20ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "idx = 0\n",
    "for i,text in enumerate(df['text']):\n",
    "    if(max_len<len(text)):\n",
    "        max_len = len(text)\n",
    "        idx = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e7a4d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4578"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384a4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_sent = len(df['text'][idx].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b2b4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1428"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f1f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is:  500001\n"
     ]
    }
   ],
   "source": [
    "vocab = model.index_to_key\n",
    "key_to_idx = model.key_to_index\n",
    "vocab_size = len(vocab) + 1\n",
    "print(\"Vocabulary size is: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3ccfb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "np.random.seed(0)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c3ab63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, model, max_len):\n",
    "\n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (â‰ˆ 1 line)\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "        sentence_words = X[i].split()\n",
    "        \n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            if w in key_to_idx:\n",
    "                X_indices[i, j] = key_to_idx[w]\n",
    "                # Increment j to j + 1\n",
    "                j += 1\n",
    "            else:\n",
    "                j+=1\n",
    "            \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f74a4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(model, key_to_idx):\n",
    "    vocab = model.index_to_key\n",
    "    vocab_len = len(vocab) + 1  # adding 1 to fit Keras embedding (requirement)\n",
    "                \n",
    "    emb_dim = model[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "\n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in key_to_idx.items():\n",
    "        emb_matrix[index, :] = model[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False. \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6ab4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape, model, key_to_idx):\n",
    "\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors (â‰ˆ1 line)\n",
    "    embedding_layer = pretrained_embedding_layer(model, key_to_idx)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer, you get back the embeddings\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.1)(X)\n",
    "    # Propagate X trough another LSTM layer with 64-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.1)(X)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(1)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('tanh')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f247390f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1428)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1428, 300)         150000300 \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 1428, 128)         219648    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1428, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 150,351,661\n",
      "Trainable params: 351,361\n",
      "Non-trainable params: 150,000,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model = LSTM_model((max_len_sent,), model, key_to_idx)\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21e2101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(clipvalue=1, learning_rate=0.01)\n",
    "\n",
    "Model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c85d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import shuffle\n",
    "#df = shuffle(df, random_state=51)\n",
    "#df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd2b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part = int(df.shape[0]*0.75)\n",
    "\n",
    "#train_df = df.loc[0:part]\n",
    "#train_df.reset_index(drop=True, inplace=True)\n",
    "#train_df.to_csv('corpus_lemm_train.csv', index=False)\n",
    "#ytrain = df.loc[0:part, 'fraudulent']\n",
    "#test_df = df.loc[part:]\n",
    "#test_df.reset_index(drop=True, inplace=True)\n",
    "#test_df.to_csv('corpus_lemm_test.csv', index=False)\n",
    "#ytest = df.loc[part: , 'fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76a56f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('corpus_lemm_train.csv')\n",
    "xtrain = train_df['text']\n",
    "ytrain = train_df['fraudulent']\n",
    "\n",
    "test_df = pd.read_csv('corpus_lemm_test.csv')\n",
    "xtest = test_df['text']\n",
    "ytest = test_df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a6560db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(xtrain, key_to_idx, max_len_sent)\n",
    "Y_train_oh = ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a508e5fb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "98/98 [==============================] - 2382s 24s/step - loss: 0.5105 - accuracy: 0.9669\n",
      "Epoch 2/2\n",
      "98/98 [==============================] - 3177s 32s/step - loss: 0.5105 - accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b1bd64db50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(X_train_indices, Y_train_oh, epochs = 2, batch_size = 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9799f264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./MyModel_lem_long\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./MyModel_lem_long\\assets\n"
     ]
    }
   ],
   "source": [
    "Model.save('./MyModel_lem_long',save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf4f8cfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('MyModel_tf1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74c62d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 152s 4s/step - loss: 0.4461 - accuracy: 0.9711\n",
      "\n",
      "Test accuracy =  0.9710773825645447\n"
     ]
    }
   ],
   "source": [
    "xtest.reset_index(drop=True, inplace=True)\n",
    "X_test_indices = sentences_to_indices(xtest, key_to_idx, max_len = max_len_sent)\n",
    "loss, acc = Model.evaluate(X_test_indices, ytest, batch_size=128)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6a7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
